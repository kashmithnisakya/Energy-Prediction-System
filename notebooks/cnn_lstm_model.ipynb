{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e87ffeca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 23:06:38.886716: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3c83278",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH      = \"../ml/data/processed/china_mill_data_2025_03_04_09_30_30.csv\"\n",
    "COL_NAME      = \"energy\"\n",
    "SPLIT_RATIO   = 0.8\n",
    "SHUFFLE_BUF   = 1_000\n",
    "\n",
    "# You can tune these, or leave defaults for Keras-Tuner to override:\n",
    "DEFAULT_WINDOW = 60\n",
    "DEFAULT_BATCH  = 32\n",
    "EPOCHS         = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc227a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "series = df[COL_NAME].astype(np.float32).values\n",
    "\n",
    "split_idx   = int(len(series) * SPLIT_RATIO)\n",
    "train_series = series[:split_idx]\n",
    "val_series   = series[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fa596a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1])) \n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f7e1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 23:09:05.003878: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-23 23:09:05.004153: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "train_ds = windowed_dataset(train_series, DEFAULT_WINDOW, DEFAULT_BATCH, SHUFFLE_BUF)\n",
    "val_ds   = windowed_dataset(val_series,   DEFAULT_WINDOW, DEFAULT_BATCH, SHUFFLE_BUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(window_size, \n",
    "                conv_filters=64, \n",
    "                lstm_units=64, \n",
    "                dropout_rate=0.2, \n",
    "                learning_rate=1e-3):\n",
    "    x   = tf.keras.Input(shape=(window_size,1))\n",
    "    x   = tf.keras.layers.Conv1D(conv_filters, 5, padding=\"causal\", activation=\"relu\")(x)\n",
    "    x   = tf.keras.layers.LSTM(lstm_units, return_sequences=True)(x)\n",
    "    x   = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    x   = tf.keras.layers.LSTM(lstm_units)(x)\n",
    "    x   = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    out = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(inp, out, name=\"energy_forecaster\")\n",
    "\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.Huber(),\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb18c5a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.api._v2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEFAULT_WINDOW\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(window_size, conv_filters, lstm_units, dropout_rate, learning_rate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_model\u001b[39m(window_size,\n\u001b[1;32m      2\u001b[0m                 conv_filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      3\u001b[0m                 lstm_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m      4\u001b[0m                 dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m      5\u001b[0m                 learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[1;32m      7\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mConv1D(conv_filters, \u001b[38;5;241m5\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcausal\u001b[39m\u001b[38;5;124m\"\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(lstm_units, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m      9\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(dropout_rate),\n\u001b[1;32m     10\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTM(lstm_units),\n\u001b[1;32m     11\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDropout(dropout_rate),\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# 3) final forecaster\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m     ], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_forecaster\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     17\u001b[0m         loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mHuber(),\n\u001b[1;32m     18\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate),\n\u001b[1;32m     19\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda/envs/TF_GPU/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:58\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m---> 58\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[0;32m~/miniconda/envs/TF_GPU/lib/python3.10/site-packages/tensorflow/python/util/lazy_loader.py:41\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/TF_GPU/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:992\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.api._v2'"
     ]
    }
   ],
   "source": [
    "model = build_model(DEFAULT_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71182ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da66290",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # 1) Stop early if no improvement on val_mae\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_mae\", patience=10, restore_best_weights=True\n",
    "    ),\n",
    "    # 2) Reduce LR when plateau\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_mae\", factor=0.5, patience=5, min_lr=1e-6\n",
    "    ),\n",
    "    # 3) Save checkpoint every epoch\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"models/epoch_{epoch:02d}.h5\",\n",
    "        save_best_only=False\n",
    "    ),\n",
    "    # 4) TensorBoard\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"logs/energy\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a65bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tuner_model(hp):\n",
    "    ws = hp.Int(\"window_size\", 30, 3360, step=30)         # can tune from 0.5h up to a week\n",
    "    cf = hp.Choice(\"conv_filters\", [32, 64, 128])\n",
    "    lu = hp.Choice(\"lstm_units\",   [32, 64, 128])\n",
    "    dr = hp.Float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    lr = hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"log\")\n",
    "\n",
    "    # rebuild datasets with this window size\n",
    "    train_ds_t = windowed_dataset(train_series, ws, DEFAULT_BATCH, SHUFFLE_BUF)\n",
    "    val_ds_t   = windowed_dataset(val_series,   ws, DEFAULT_BATCH, SHUFFLE_BUF)\n",
    "\n",
    "    m = build_model(ws, conv_filters=cf, lstm_units=lu, dropout_rate=dr, learning_rate=lr)\n",
    "    m.fit(\n",
    "        train_ds_t,\n",
    "        validation_data=val_ds_t,\n",
    "        epochs=20,         # short for tuning\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(monitor=\"val_mae\", patience=5, restore_best_weights=True)\n",
    "        ],\n",
    "        verbose=0\n",
    "    )\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9da5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = kt.Hyperband(\n",
    "    build_tuner_model,\n",
    "    objective=\"val_mae\",\n",
    "    max_epochs=50,\n",
    "    factor=3,\n",
    "    directory=\"ktuner\",\n",
    "    project_name=\"energy_forecast\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58313762",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hp    = tuner.get_best_hyperparameters(1)[0]\n",
    "best_model = tuner.get_best_models(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best window_size:\",     best_hp.get(\"window_size\"))\n",
    "print(\"Best conv_filters:\",    best_hp.get(\"conv_filters\"))\n",
    "print(\"Best lstm_units:\",      best_hp.get(\"lstm_units\"))\n",
    "print(\"Best dropout_rate:\",    best_hp.get(\"dropout\"))\n",
    "print(\"Best learning_rate:\",   best_hp.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0581720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws       = best_hp.get(\"window_size\")\n",
    "train_ds = windowed_dataset(train_series, ws, DEFAULT_BATCH, SHUFFLE_BUF)\n",
    "val_ds   = windowed_dataset(val_series,   ws, DEFAULT_BATCH, SHUFFLE_BUF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2067c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cb27b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history[\"loss\"],      label=\"train loss\")\n",
    "plt.plot(history.history[\"val_loss\"],  label=\"val loss\")\n",
    "plt.plot(history.history[\"mae\"],       label=\"train mae\")\n",
    "plt.plot(history.history[\"val_mae\"],   label=\"val mae\")\n",
    "plt.legend(); plt.grid(True); plt.title(\"History\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478ec0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_b, y_b in val_ds.take(1):\n",
    "    preds = best_model.predict(x_b)\n",
    "    hist  = x_b[0,:,0].numpy()\n",
    "    true  = y_b[0].numpy()\n",
    "    pred  = preds[0,0]\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(range(ws), hist, label=\"history\")\n",
    "    plt.scatter(ws, true, c=\"green\", label=\"true next\")\n",
    "    plt.scatter(ws, pred, c=\"red\",   label=\"predicted next\")\n",
    "    plt.legend(); plt.grid(True); plt.title(\"Demo Prediction\")\n",
    "    plt.show()\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
